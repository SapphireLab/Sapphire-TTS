# 第06章.使用训练工具

[代码文件](PythonFiles/Ch06.Trainer.py)

注意: 本章内容经过重排

## 6.1.介绍

HuggingFace 提供了巨大的模型库, 虽然其中的很多模型性能表现出色, 但这些模型往往是在广义的数据集上训练的, 缺乏针对特定数据集的优化, 所以在获得一个合适的模型后, 往往还需要针对具体任务的特定数据集进行二次训练, 即迁移学习.

迁移学习的训练难度低, 要求的数据量少, 对计算资源的要求也低.

HuggingFace 提供了训练工具, 同意了模型的再训练过程, 使调用者无需了解具体模型的计算过程, 只需针对具体的任务准备好数据集, 便可以再训练模型.

本章使用情感分类任务的例子进行再训练, 以此讲解 HuggingFace 训练工具的使用方法.

## 6.2.使用

### 6.2.1.准备数据集

首先加载一个编码工具, 由于编码工具和模型往往是成对使用的, 因此此处使用 `hfl/rbt3` 编码工具并再训练 `hfl/rbt3` 模型.

```python
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("hfl/rbt3")
print("分词器试运行".center(50, "="))
tokenize_result = tokenizer.batch_encode_plus(
    batch_text_or_text_pairs = ["明月装饰了你的窗子", "你装饰了别人的梦"],
    truncation               = True)
print(tokenize_result)
运行结果:
======================分词器试运行======================
{
    'input_ids': [
        [101, 3209, 3299, 6163, 7652, 749, 872, 4638, 4970, 2094, 102], 
        [101, 872, 6163, 7652, 749, 1166, 782, 4638, 3457, 102]], 
    'token_type_ids': [
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],
    'attention_mask': [
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]
}
```

然后加载一个数据集, 使用该数据集再训练模型.

```python
from datasets import load_dataset

print("加载数据集".center(50, "="))
dataset_path = r"D:\Speech\_Datasets\Seamew_ChnSentiCorp"
dataset = load_dataset(dataset_path)
print(dataset)
print("打乱并选取数据集".center(50, "="))
dataset['train'] = dataset['train'].shuffle().select(range(2000))
dataset['test']  = dataset['test'].shuffle().select(range(100))
print(dataset)
运行结果:
======================加载数据集=======================
DatasetDict({
    train: Dataset({
        features: ['label', 'text'],
        num_rows: 9600
    })
    validation: Dataset({
        features: ['label', 'text'],
        num_rows: 1200
    })
    test: Dataset({
        features: ['label', 'text'],
        num_rows: 1200
    })
})
=====================打乱并选取数据集=====================
DatasetDict({
    train: Dataset({
        features: ['label', 'text'],
        num_rows: 2000
    })
    validation: Dataset({
        features: ['label', 'text'],
        num_rows: 1200
    })
    test: Dataset({
        features: ['label', 'text'],
        num_rows: 100
    })
})
```

对文本数据编码成数组形式:

```python
print("编码数据集".center(50, "="))
def encode(data):
    return tokenizer.batch_encode_plus(data['text'], truncation=True)
dataset = dataset.map(encode, batched=True, batch_size=1000, num_proc=1, remove_columns=['text'])
print(dataset)
运行结果:
======================编码数据集=======================
Map: 100%|██████████| 2000/2000 [00:00<00:00, 11874.01 examples/s]
Map: 100%|██████████| 100/100 [00:00<00:00, 5016.69 examples/s]
DatasetDict({
    train: Dataset({
        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],
        num_rows: 2000
    })
    validation: Dataset({
        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],
        num_rows: 1200
    })
    test: Dataset({
        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],
        num_rows: 100
    })
})
```

由于模型对句子的长度有限制, 不能处理长度超过 512 的句子, 所以需要进一步处理.
此处选择丢弃法, 过滤掉长度过长的句子.

```python
print("过滤长数据".center(50, "="))
def remove_too_long(data):
    return [(len(i)) <= 512 for i in data['input_ids']]
dataset = dataset.filter(remove_too_long, batched=True, batch_size=1000, num_proc=1)
print(dataset)
运行结果:
======================过滤长数据=======================
Filter: 100%|██████████| 2000/2000 [00:00<00:00, 27446.13 examples/s]
Filter: 100%|██████████| 100/100 [00:00<00:00, 9123.80 examples/s]
DatasetDict({
    train: Dataset({
        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],
        num_rows: 1972
    })
    validation: Dataset({
        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],
        num_rows: 1190
    })
    test: Dataset({
        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],
        num_rows: 99
    })
})
```

此外可以选择截断超出长度的部分, 开头或结尾均可.

### 6.2.2.定义模型和训练工具

加载由哈尔滨工业大学科大讯飞联合实验室发布的 `hfl/rbt3` 模型, 这是一个基于中文文本数据训练的 BERT 模型.
后续将使用准备好的数据集对模型进行再训练.
该模型具有约 3800 万个参数, 是一个较小的模型.

```python
print("加载模型".center(50, "="))
model = AutoModelForSequenceClassification.from_pretrained("hfl/rbt3", num_labels=2)
print(f"{sum([p.numel() for p in model.parameters()]) / 10000}" + "万参数")
运行结果:
=======================加载模型=======================
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/rbt3 and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
3847.8338万参数
```

模型的输出主要包括两个部分: loss 和 logits.
不同模型输出的内容不同, 但一般都会包含 loss, 所以使用 HuggingFace 模型时无需自行计算 loss.
而是由模型自行封装, 方便模型的再训练.

```python
print("模型推理测试".center(50, "="))
data = {
    'input_ids': torch.ones(4, 10, dtype=torch.long),
    'token_type_ids': torch.ones(4, 10, dtype=torch.long),
    'attention_mask': torch.ones(4, 10, dtype=torch.long),
    'labels': torch.ones(4, dtype=torch.long)
}
out = model(**data)
print(f"{out['loss']=}, {out['logits'].shape=}")
运行结果:
======================模型推理测试======================
out['loss']=tensor(0.6397, grad_fn=<NllLossBackward0>), 
out['logits'].shape=torch.Size([4, 2])
```

为了便于在训练过程中观察模型的性能变化, 需要定义一个评价指标函数.
对于情感分类任务, 往往关注正确率指标, 所以需要加载正确率评价函数

```python
print("加载评价函数".center(50, "="))
metric = load_metric("accuracy")
def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = predictions.argmax(axis=-1)
    return metric.compute(predictions=predictions, references=labels)
print("评价函数试运行".center(50, "="))
eval_pred = EvalPrediction(
    predictions=np.array([[0,1],[2,3],[4,5],[6,7]]),
    label_ids=np.array([1,1,0,1])
)
print(compute_metrics(eval_pred))
运行结果:
======================加载评价函数======================
~\datasets\load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. 
You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.
  warnings.warn(
=====================评价函数试运行======================
{'accuracy': 0.75}
```

数据整理函数使用了 HuggingFace 提供的 DataCollatorWithPadding 对象, 能把一个批次中长短不一的句子补充成一个统一的长度, 该长度取决于批次中最长的句子长度, 从而整理成矩阵形式.

```python
print("定义整理函数".center(50, "="))
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)
print("数据整理试运行".center(50, "="))
data = dataset['train'][:5]
for i in data['input_ids']:
    print(len(i))
data = data_collator(data)
for k, v in data.items():
    print(k, v.shape)
print(tokenizer.decode(data['input_ids'][0]))
运行结果:
======================定义整理函数======================
=====================数据整理试运行======================
79
40
111
171
34
input_ids torch.Size([5, 171])
token_type_ids torch.Size([5, 171])
attention_mask torch.Size([5, 171])
labels torch.Size([5])
[CLS] 散 热 整 体 还 可 以 ， 就 是 触 摸 板 有 些 热 呀 。 今 天 充 电 的 时 间 有 点 长 ， 开 机 的 键 似 乎 有 点 漏 电 ， 摸 上 去 手 指 有 点 麻 麻 的 ， 拔 掉 电 源 以 及 晚 上 充 电 时 用 电 脑 就 没 有 什 么 事 ， 很 奇 怪 [UNK] [UNK] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]
```

在开始训练之前需要定义好超参数.
HuggingFace 使用 TrainingArguments 对象来封装超参数.
该对象可以封装的超参数很多, 但除了输出文件夹外其他超参数都有默认值, 建议参阅 HuggingFace 文档.

```python
print("定义超参数".center(50, "="))
output_dir = r"./results"
os.makedirs(output_dir, exist_ok=True)
args = TrainingArguments(
    output_dir                  = output_dir,
    evaluation_strategy         = 'steps',
    eval_steps                  = 30,
    save_strategy               = 'steps',
    save_steps                  = 30,
    num_train_epochs            = 1,
    learning_rate               = 1e-4,
    weight_decay                = 1e-2,
    per_device_eval_batch_size  = 16,
    per_device_train_batch_size = 16,
    no_cuda                     = False,
    save_safetensors            = False
)
```

完成了上述准备工作, 下面定义训练器, 需要传入待训练模型, 超参数对象, 训练集, 验证集, 评价函数, 数据整理函数.
注意: `save_safetensors` 参数为 True 则会保存为 `safetensors` 文件否则为 `pytorch_model.bin`.

```python
print("定义训练器".center(50, "="))
trainer = Trainer(
    model           = model,
    args            = args,
    train_dataset   = dataset['train'],
    eval_dataset    = dataset['test'],
    compute_metrics = compute_metrics,
    data_collator   = data_collator
)
```

### 6.2.3.训练和测试

训练前先对模型进行一次测试, 先定下训练前的基准, 在训练结束后再进行对比, 以验证训练的有效性.

注意: 需要安装 Accelerate 库.

```python
print("训练前评估".center(50, "="))
print(trainer.evaluate())
print("开始训练".center(50, "="))
trainer.train()
print("训练后评估".center(50, "="))
print(trainer.evaluate())
运行结果:
======================训练前评估=======================
100%|██████████| 7/7 [00:00<00:00, 45.90it/s]
{
    'eval_loss'              : 0.7201959490776062,
    'eval_accuracy'          : 0.3434343434343434,
    'eval_runtime'           : 1.1781,
    'eval_samples_per_second': 84.036,
    'eval_steps_per_second'  : 5.942
}
======================开始训练=========================
 24%|██▍       | 30/124 [00:02<00:07, 11.84it/s]
{
    'eval_loss'              : 0.28076228499412537,
    'eval_accuracy'          : 0.9191919191919192,
    'eval_runtime'           : 0.2242,
    'eval_samples_per_second': 441.473,
    'eval_steps_per_second'  : 31.215,
    'epoch'                  : 0.24
}                                               
 48%|████▊     | 60/124 [00:06<00:06,  9.65it/s]
{
    'eval_loss'              : 0.26336410641670227,
    'eval_accuracy'          : 0.9191919191919192,
    'eval_runtime'           : 0.2198,
    'eval_samples_per_second': 450.442,
    'eval_steps_per_second'  : 31.849,
    'epoch'                  : 0.48
}                                               
 73%|███████▎  | 90/124 [00:09<00:02, 12.96it/s]
{
    'eval_loss'              : 0.22658783197402954,
    'eval_accuracy'          : 0.8888888888888888,
    'eval_runtime'           : 0.2193,
    'eval_samples_per_second': 451.504,
    'eval_steps_per_second'  : 31.925,
    'epoch'                  : 0.73
}                                                
 97%|█████████▋| 120/124 [00:13<00:00,  9.46it/s]
{
    'eval_loss'              : 0.2059161514043808,
    'eval_accuracy'          : 0.9191919191919192,
    'eval_runtime'           : 0.221,
    'eval_samples_per_second': 447.958,
    'eval_steps_per_second'  : 31.674,
    'epoch'                  : 0.97
}
100%|██████████| 124/124 [00:14<00:00,  8.77it/s]
{
    'train_runtime'           : 14.1454,
    'train_samples_per_second': 139.41,
    'train_steps_per_second'  : 8.766,
    'train_loss'              : 0.4551481739167244,
    'epoch'                   : 1.0
}
======================训练后评估=======================
100%|██████████| 7/7 [00:00<00:00, 44.29it/s]
{
    'eval_loss'              : 0.20556524395942688,
    'eval_accuracy'          : 0.9191919191919192,
    'eval_runtime'           : 0.205,
    'eval_samples_per_second': 482.937,
    'eval_steps_per_second'  : 34.147,
    'epoch'                  : 1.0
}
```

加载检查点:
```python
trainer.train(
    resume_from_checkpoint=os.path.join(output_dir, "checkpoint-90"),
)
```

保存模型:
```python
trainer.save_model(output_dir=output_dir)
```

预测:
```python
print("推理测试".center(50, "="))
import torch
from safetensors.torch import load_file

if os.path.exists(os.path.join(output_dir, "model.safetensors")):
    model.load_state_dict(load_file(os.path.join(output_dir, "model.safetensors")))
elif os.path.exists(os.path.join(output_dir, "pytorch_model.bin")):
    model.load_state_dict(torch.load(os.path.join(output_dir, "pytorch_model.bin")))
else:
    raise FileNotFoundError("模型文件不存在")
model.eval()
for i, data in enumerate(trainer.get_eval_dataloader()):
    break
out = model(**data)
out = out['logits'].argmax(axis=-1)
for i in range(8):
    print(tokenizer.decode(data['input_ids'][i], skip_special_tokens=True))
    print('label=', data['labels'][i].item())
    print('pred=', out[i].item())
运行结果:
=======================推理测试=======================
8 月 份 为 签 证 ， 入 住 该 旅 馆 ， 也 许 是 首 都 北 京 吧 ， 260 元 一 夜 ， 只 会 想 住 一 次 的 ， 一 切 都 是 那 么 旧 ， 好 像 260 元 钱 不 是 钱 似 的 。
label= 0
pred= 0
房 间 很 大 ， 交 通 方 便 。 早 餐 还 可 以 。 下 次 去 沈 阳 ， 还 是 住 那 。 补 充 点 评 2007 年 12 月 25 日 ： 贵 了 一 点 ， 如 果 不 是 公 司 付 账 不 会 住 那 。
label= 1
pred= 1
为 了 高 兴 我 买 了 第 二 个 小 白 ， 这 个 小 白 安 静 ， 不 爱 叫 ， 外 皮 漂 亮 ， 得 常 擦 擦 ， 长 的 也 紧 凑 ， 有 很 好 的 设 计 感 ， 虽 然 个 子 小 ， 什 么 都 安 得 上 ， 装 了 不 少 东 西 ， 跑 的 一 点 不 慢
label= 1
pred= 1
给 孩 子 朗 读 的 好 处 大 家 都 知 道, 关 键 是 如 何 读, 读 什 么. 书 中 举 的 例 子 都 是 国 外 的, 没 有 中 国 孩 子 的 读 书 名 单.
label= 0
pred= 0
任 何 一 本 教 材 ， 如 果 历 时 多 年 ， 不 断 改 进 ， 本 身 就 说 明 作 者 对 读 者 的 极 度 负 责 。 这 本 书 是 运 筹 学 领 域 的 入 门 佳 作 ， 也 是 名 著 。 像 我 这 种 奔 三 的 初 学 者 ， 一 口 气 看 到 晚 上 两 点 ， 看 了 100 多 页 ， 丝 毫 没 有 觉 得 枯 燥 乏 味 ， 而 感 觉 像 听 一 个 谆 谆 善 诱 的 老 师 娓 娓 道 来 ， 图 文 并 茂 之 处 ， 尽 观 究 竟 。 而 且 作 者 还 极 为 负 责 地 将 ampl 语 言 的 简 明 介 绍 附 在 书 后 ， 非 常 了 解 读 者 希 望 能 够 尽 快 上 手 实 验 的 心 态 。 无 论 如 何 ， 这 本 书 都 是 值 得 一 买 的 好 书 。
label= 1
pred= 1
非 常 不 好 ， 我 们 渡 过 了 一 个 让 人 难 以 忍 受 的 纪 念 日. com / thread - 1368750 - 1 - 2. html 补 充 点 评 2008 年 1 月 30 日 ：. com / thread - 1368750 - 1 - 2. html
label= 0
pred= 0
不 能 兑 现 预 订 的 酒 店 是 全 世 界 最 差 的 酒 店 ， 譬 如 这 家 万 里 路 国 际 青 年 酒 店 。 补 充 点 评 2008 年 1 月 14 日 ： 订 好 了 的 ， 到 了 酒 店 说 没 房 。
label= 0
pred= 0
麦 克 风 和 喇 叭 有 共 鸣 ， 合 上 盖 子 后 有 尖 锐 的 噪 音 ， 软 件 调 节 无 效 ， 是 设 计 瑕 疵 led 屏 幕 色 彩 通 病 ： 偏 红 边 角 处 理 的 一 般 ， 顶 盖 强 度 稍 差
label= 0
pred= 0
```

## 总结

本章通过一个情感分类任务讲解了 HuggingFace 训练工具的使用方法, 介绍了一般的数据集方法, 在训练过程中结合评价函数观察模型的性能变化, 并且介绍了模型的保存和加载以及预测的方法.