# BigVGAN: A Universal Neural Vocoder with Large-Scale Training

<!-- - 标题: BigVGAN: A Universal Neural Vocoder with Large-Scale Training
- 作者:
  - 01 [Sang-gil Lee](../../Authors/Sang-gil_Lee.md)
  - 02 [Wei Ping](../../Authors/Wei_Ping.md)
  - 03 [Boris Ginsburg](../../Authors/Boris_Ginsburg.md)
  - 04 [Bryan Catanzaro](../../Authors/Bryan_Catanzaro.md)
  - 05 [Sungroh Yoon](../../Authors/Sungroh_Yoon.md)
- 机构:
  - [Nvidia](../../Institutions/Nvidia.md)
- 时间:
  - 2022.06.09 ArXiv v1
  - 2023.02.16 ArXiv v2
- 链接:
  - [ArXiv](https://arxiv.org/abs/2206.04658)
  - [DOI]()
  - [Github](https://github.com/nvidia/bigvgan)
  - [Demo](https://bigvgan-demo.github.io/)
- 标签:
  - ?
- 页数: ?
- 引用: ?
- 被引: ? -->

<details>
<summary>基本信息</summary>

- 标题:
- 作者:
  - ??
- 机构:
  - 机构 
- 时间:
  - 预印时间: 20??.??.?? ArXiv v1
  - 更新笔记: 20??.??.??
- 发表:
  - 期刊/会议 
- 链接:
  - [ArXiv]()
  - [DOI]()
  - [Github]()
  - [Demo]()
  - [Scholar](https://scholar.google.com/scholar?cluster=)
- 标签:
  - ?
- 页数: ?
- 引用: ?
- 被引: ?
- 数据:
  - ? 
- 对比:
  - ?
- 复现:
  - ?

</details>

## Abstract: 摘要

> Despite recent progress in generative adversarial network~(GAN)-based vocoders, where the model generates raw waveform conditioned on acoustic features, it is challenging to synthesize high-fidelity audio for numerous speakers across various recording environments.  
> In this work, we present BigVGAN, a universal vocoder that generalizes well for various out-of-distribution scenarios without fine-tuning.
> We introduce periodic activation function and anti-aliased representation into the GAN generator, which brings the desired inductive bias for audio synthesis and significantly improves audio quality.
> In addition, we train our GAN vocoder at the largest scale up to 112M parameters, which is unprecedented in the literature. We identify and address the failure modes in large-scale GAN training for audio, while maintaining high-fidelity output without over-regularization. 
> Our BigVGAN, trained only on clean speech~(LibriTTS), achieves the state-of-the-art performance for various zero-shot~(out-of-distribution) conditions, including unseen speakers, languages, recording environments, singing voices, music,  and instrumental audio.~\footnote{Listen to audio samples from BigVGAN at: {\url{https://bigvgan-demo.github.io/}}. }
> We release our code and model at:  {\small \url{https://github.com/NVIDIA/BigVGAN}}.

## 1.Introduction: 引言

Deep generative models have demonstrated noticeable successes for modeling raw audio.
The successful methods include, autoregressive models~\citep{oord2016wavenet, mehri2016samplernn, kalchbrenner2018efficient}, flow-based models~\citep{oord2017parallel,ping2018clarinet, prenger2019waveglow, kim2018flowavenet, ping2019waveflow, lee2020nanoflow}, GAN-based models~\citep{donahue2018adversarial, kumar2019melgan,binkowski2020high, yamamoto2020parallel, kong2020hifi}, and diffusion models~\citep{kong2020diffwave, chen2020wavegrad, lee2022priorgrad}.

Among these methods, GAN-based vocoders~\citep[e.g.,][]{kong2020hifi} can generate high-fidelity raw audio conditioned on mel spectrogram, while synthesizing hundreds of times faster than real-time on a single GPU. 
However, existing GAN vocoders are confined to the settings with a moderate number of voices recorded in clean environment due to the limited model capacity. The audio quality can heavily degrade when the models are conditioned on mel spectrogram from unseen speakers in different recording environments. 
In practice, a \emph{universal vocoder}, that can do zero-shot generation for out-of-distribution samples, is very valuable in many real-world applications, including text-to-speech with numerous speakers~\citep{ping2017deep}, neural voice cloning~\citep{arik2018neural, jia2018transfer}, voice conversion~\citep{liu2018wavenet}, speech-to-speech translation~\citep{jia2019direct}, and neural audio codec~\citep{zeghidour2021soundstream}. In these applications, the neural vocoder also needs to generalize well for audio recorded at various conditions.

Scaling up the model size for zero-shot performance is a noticeable trend in text generation~\citep[e.g.,][]{brown2020language} and image synthesis~\citep[e.g.,][]{ramesh2021zero}, but has not been explored in audio synthesis.
Although likelihood-based models are found to be easier for scaling among others because of their simple training objective and stable optimization, we build our universal vocoder with large-scale GAN training, because GAN vocoder has the following advantages:
\emph{i}) In contrast to autoregressive or diffusion models, it is fully parallel and requires only one forward pass to generate high-dimensional waveform.
\emph{ii}) In contrast to flow-based models~\citep{prenger2019waveglow}, it does not enforce any architectural constraints~(e.g., affine coupling layer) that maintain the bijection between latent and data. 
Such architectural constraints can limit model capacity given the same number of parameters~\citep{ping2019waveflow}.

In this work, we present \emph{BigVGAN}, a \emph{Big}  \emph{V}ocoding \emph{GAN} that enables high-fidelity out-of-distribution~(OOD) generation without fine-tuning. 
Specifically, we make the following contributions:

- We introduce periodic activations into the generator, which provide the desired inductive bias for audio synthesis. 
Inspired by the methods proposed for other domains~\citep{liu2020neural, sitzmann2020implicit}, we demonstrate the noticeable success of periodic activations in audio synthesis.

- We propose anti-aliased multi-periodicity composition~(AMP) module for modeling complex audio waveform. AMP composes multiple signal components with learnable periodicities and uses low-pass filter to reduce the high-frequency artifacts.

- We successfully scale BigVGAN up to 112M parameters by fixing the failure modes of large-scale GAN training without regularizing both generator and discriminator. The empirical insights are different from \citet{brock2018large} in image domain. For example, regularization methods~\citep[e.g.,][]{miyato2018spectral} introduce phase mismatch artifacts in audio synthesis. 

- We demonstrate that BigVGAN-base with 14M parameters outperforms the state-of-the-art neural vocoders with comparable size for both in-distribution and out-of-distribution samples.
In particular, BigVGAN with 112M parameters outperforms the state-of-the-art models by a large margin for zero-shot generation at various OOD scenarios, including unseen speakers, novel languages,  singing voices, music and instrumental audio in varied unseen recording environments. % It synthesizes 24 kHz high-fidelity speech 44.72~$\times$ faster than real-time on a V100 GPU.

We organize the rest of the paper as follows.
We discuss related work in \S~\ref{sec:related_work} and present BigVGAN in \S~\ref{sec:method}.
We report empirical results in \S~\ref{sec:results} and conclude the paper in \S~\ref{sec:conclusion}.

## 2.Related Works: 相关工作

Our work builds upon the state-of-the-art of GANs for image and audio synthesis.  

GAN was first proposed for image synthesis~\citep{goodfellow2014generative}. Since then, impressive results have been obtained through optimized architectures~\citep[e.g.,][]{radford2015unsupervised, karras2021alias} or large scale training~\citep[e.g.,][]{brock2018large}.

In audio synthesis, previous works focus on improving the discriminator architectures or adding new auxiliary training losses.
MelGAN~\citep{kumar2019melgan} introduces the multi-scale discriminator~(MSD) that uses average pooling to downsample the raw waveform at multiple scales and applies window-based discriminators at each scale separately. It also enforces the mapping between input mel spectrogram and generated waveform via an $\ell_1$ feature matching loss from discriminator.
In contrast, GAN-TTS~\citep{binkowski2020high} uses an ensemble of discriminators which operate on random windows of different sizes, and enforces the mapping between the conditioner and waveform adversarially using conditional discriminators.
Parallel WaveGAN~\citep{yamamoto2020parallel} extends the single short-time Fourier transform (STFT) loss~\citep{ping2018clarinet} to multi-resolution, and adds it as an auxiliary loss for GAN training.
\cite{yang2021multi} and \cite{mustafa2021stylemelgan} further improve MelGAN by incorporating the multi-resolution STFT loss.

HiFi-GAN~\citep{kong2020hifi} reuses the MSD from MelGAN, and introduces the multi-period discriminator~(MPD) for high-fidelity synthesis. 
UnivNet~\citep{jang2020universal, jang2021univnet} uses the multi-resolution discriminator~(MRD) that takes the multi-resolution spectrograms as the input and can sharpen the spectral structure of synthesized waveform.
In contrast, CARGAN~\citep{morrison2021chunked} incorporates the partial autoregression~\citep{ping2019waveflow} into generator to improve the pitch and periodicity accuracy.

In this work, we focus on improving and scaling up the generator. We introduce the periodic inductive bias for audio synthesis and address the feature aliasing issues within the non-autoregressive generator architecture. Our architectural design  has a connection with the latest results in time-series prediction~\citep{liu2020neural}, {implicit neural representations~\citep{sitzmann2020implicit}}, and image synthesis~\citep{karras2021alias}.
Note that, \citet{you2021gan} argues that different generator architectures can perform equally well for single-speaker neural vocoding.
We demonstrate that improving generator architecture is  crucial for universal neural vocoding in challenging conditions.

There are limited successes for universal neural vocoding due to the noticeable challenges.
In previous work, WaveRNN has been applied for universal vocoding task~\citep{lorenzo2018towards, paul2020speaker}. \citet{jiao2021universal} builds the  universal vocoder with flow-based model.
GAN vocoder is found to be a good candidate recently~\citep{jang2021univnet}.

## 3.Methodology: 方法

In this section, we introduce the preliminaries for GAN vocoder, then present the BigVGAN. See Figure~\ref{fig_model_diagram} for an illustration and refer to the Appendix \ref{appendix:arch_detail} for a detailed description of the architecture.

## Preliminaries of GAN Vocoder



## 4.Experiments: 实验

## 5.Results: 结果

## 6.Conclusions: 结论
